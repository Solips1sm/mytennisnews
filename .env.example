# App
NEXT_PUBLIC_APP_URL=http://localhost:3000
NEXT_PUBLIC_PREVIEW_MODE=false

# Safety toggles (override per-command when you really intend to write)
DRY_RUN=true
INGEST_DEBUG=false
INGEST_DEBUG_SAVE_HTML=false

# Sanity (v3)
# Get from https://manage.sanity.io/ > your project > API
SANITY_PROJECT_ID=
SANITY_DATASET=production
# Tokens are server-only. Never put them in cms/.env
SANITY_API_READ_TOKEN=
SANITY_API_WRITE_TOKEN=

# Database (local Postgres or Supabase)
DATABASE_URL=
# Local example: postgresql://postgres:postgres@localhost:5432/mytennisnews
# Supabase pooled (PgBouncer) examples (recommended for app runtime):
#   - Standard username:   postgresql://postgres:<password>@aws-1-<region>.pooler.supabase.com:6543/postgres?pgbouncer=true&sslmode=require&connection_limit=1
#   - Project-ref user:    postgresql://postgres.<project_ref>:<password>@aws-1-<region>.pooler.supabase.com:6543/postgres?pgbouncer=true
# Supabase direct (for migrations/admin):
# DIRECT_URL="postgresql://postgres:<password>@db.<project_ref>.supabase.co:5432/postgres?sslmode=require"

# Prisma note: prisma/schema.prisma uses directUrl for migrations when set; app/runtime should use pooled DATABASE_URL.

# Supabase direct DB connection (server-side Prisma)
# If NEXT_PUBLIC_SUPABASE_URL is set, SUPABASE_DB_HOST can be derived automatically.
# Otherwise set SUPABASE_DB_HOST to e.g. db.<ref>.supabase.co
SUPABASE_DB_HOST=
SUPABASE_DB_NAME=postgres
SUPABASE_DB_USER=postgres
SUPABASE_DB_PASSWORD=
# If you want to use pooler (IPv4 / serverless), set:
# SUPABASE_USE_POOLER=true
# SUPABASE_DB_HOST=aws-1-<region>.pooler.supabase.com
# SUPABASE_DB_PORT=6543
# SUPABASE_DB_USER=postgres.<ref>

# Auth (NextAuth.js)
NEXTAUTH_URL=http://localhost:3000
NEXTAUTH_SECRET=

# Email provider for magic links
EMAIL_SERVER_HOST=smtp.gmail.com
EMAIL_SERVER_PORT=587
EMAIL_SERVER_USER=
EMAIL_SERVER_PASSWORD=
EMAIL_FROM=noreply@example.com

# Email (later)
RESEND_API_KEY=

# Optional caching (later)
UPSTASH_REDIS_REST_URL=
UPSTASH_REDIS_REST_TOKEN=

# AI (OpenAI)
# Server-only key. Do not commit your real key.
OPENAI_API_KEY=
# Default model for AI pipeline. Override in local .env.
AI_MODEL=gpt-5-mini

# Supabase (public, for future client usage)
NEXT_PUBLIC_SUPABASE_URL=
NEXT_PUBLIC_SUPABASE_ANON_KEY=

# Ingestion feed defaults
# You can configure a single feed:
# FEED_NAME=ESPN Tennis
# FEED_URL=https://www.espn.com/espn/rss/tennis/news
# Or multiple feeds (comma-separated): NAME|TYPE|URL (TYPE defaults to rss)
# FEEDS=ESPN Tennis|rss|https://www.espn.com/espn/rss/tennis/news, ATP|rss|https://www.atptour.com/en/media/rss-feed/xml-feed
# Enable fetching canonical article pages for enriched fields (body, images) stored only in DB ledger
INGEST_FETCH_ARTICLE=false
# Control writing to CMS body field (Portable Text) for drafts:
# - none: do not write body content
# - summary: write a short summary from extracted text + disclaimer + canonical link
# - full: write full extracted text + disclaimer + canonical link (only if you have permission)
INGEST_WRITE_BODY=none
# When using summary mode, cap body length
INGEST_BODY_MAX_CHARS=1200

# Rendered fetch controls (enable headless browser fetching for heavy pages)
# INGEST_RENDERED=true
# INGEST_RENDERED_HOSTS=espn.com,atptour.com
# INGEST_RENDERED_DRIVER=puppeteer         # or real-browser
# INGEST_PUPPETEER_HEADLESS=true
# INGEST_REAL_BROWSER_HEADLESS=shell       # true | false | shell
# INGEST_REAL_BROWSER_CHROME_PATH=
# INGEST_REAL_BROWSER_XVFB=true

# Refresh mode: re-extract and update existing ledger entries and Sanity drafts
# When true, items already ingested (by URL hash) will be UPDATED rather than skipped.
# This will patch draft body/excerpt based on current extraction and write settings.
INGEST_REFRESH=false

# Cron automation (Vercel Scheduled Functions or other task runners)
# Secret shared with the cron job (Bearer <CRON_SECRET> header or ?secret= query param)
CRON_SECRET=
# Optional comma-separated preset keys overriding defaults (espn, atp, wta)
# CRON_FEEDS=espn,atp,wta
# Limit concurrent AI runs to avoid rate limits (defaults to 2)
# CRON_AI_CONCURRENCY=2
# Skip the AI backfill step entirely when true (default false)
# CRON_AI_SKIP=true
# Limit the number of articles processed by the AI backfill per run.
# Defaults to 2 when unset; set to 0 for no cap.
# CRON_AI_LIMIT=2
# Automatically chain follow-up cron runs when backlog remains (optional)
# CRON_SELF_TRIGGER_URL=https://www.mytennisnews.com/api/cron-cycle
# Wait time (ms) before dispatching follow-up (e.g. 260000 for ~4m20s)
# CRON_SELF_TRIGGER_DELAY_MS=260000
# Maximum self-trigger depth to avoid infinite loops (default 10)
# CRON_SELF_TRIGGER_MAX=12
# Safety window (ms) within the 300s runtime budget for delay calculations
# CRON_SELF_TRIGGER_SAFE_WINDOW_MS=285000
